(window.webpackJsonp=window.webpackJsonp||[]).push([[42],{728:function(t,e,a){"use strict";a.r(e);var s=a(81),r=Object(s.a)({},(function(){var t=this,e=t._self._c;return e("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[e("h1",{attrs:{id:"redis之缓存穿透、击穿、雪崩"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#redis之缓存穿透、击穿、雪崩"}},[t._v("#")]),t._v(" Redis之缓存穿透、击穿、雪崩")]),t._v(" "),e("p",[t._v("前言")]),t._v(" "),e("p",[t._v("设计一个缓存系统，不得不要考虑的问题就是：缓存穿透、缓存击穿与失效时的雪崩效应。")]),t._v(" "),e("blockquote",[e("p",[t._v("平时也知道这几个概念，比较容易弄混，想用比较通俗的语言记录下来。")])]),t._v(" "),e("h2",{attrs:{id:"缓存穿透"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#缓存穿透"}},[t._v("#")]),t._v(" 缓存穿透")]),t._v(" "),e("blockquote",[e("p",[t._v("比如查询一个不存在用户id，总是会穿透缓存，到达数据库层面。")])]),t._v(" "),e("p",[t._v("缓存穿透是指查询一个一定不存在的数据，由于缓存是不命中时被动写的，并且出于容错考虑，\n如果从存储层查不到数据则不写入缓存，这将导致这个不存在的数据每次请求都要到存储层去查询，\n失去了缓存的意义。在流量大时，可能DB就挂掉了，要是有人利用不存在的key频繁攻击我们的应用，这就是漏洞。")]),t._v(" "),e("h3",{attrs:{id:"解决方案"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#解决方案"}},[t._v("#")]),t._v(" 解决方案")]),t._v(" "),e("p",[t._v("有很多种方法可以有效地解决缓存穿透问题，最常见的则是采用布隆过滤器，将所有可能存在的数据哈希到一个足够大的bitmap中，一个一定不存在的数据会被 这个bitmap拦截掉，从而避免了对底层存储系统的查询压力。另外也有一个更为简单粗暴的方法（我们采用的就是这种），如果一个查询返回的数据为空（不管是数 据不存在，还是系统故障），我们仍然把这个空结果进行缓存，但它的过期时间会很短，最长不超过五分钟。")]),t._v(" "),e("h2",{attrs:{id:"缓存击穿"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#缓存击穿"}},[t._v("#")]),t._v(" 缓存击穿")]),t._v(" "),e("p",[t._v("对于一些设置了过期时间的key，如果这些key可能会在某些时间点被超高并发地访问，是一种非常“热点”的数据。这个时候，需要考虑一个问题：缓存被“击穿”的问题，这个和缓存雪崩的区别在于这里针对某一key缓存，前者则是很多key。")]),t._v(" "),e("p",[t._v("缓存在某个时间点过期的时候，恰好在这个时间点对这个Key有大量的并发请求过来，这些请求发现缓存过期一般都会从后端DB加载数据并回设到缓存，这个时候大并发的请求可能会瞬间把后端DB压垮。")]),t._v(" "),e("blockquote",[e("p",[t._v("当并发过于高的时候，热点key过期，导致一瞬间很多请求全部打在底层DB上。")])]),t._v(" "),e("h3",{attrs:{id:"解决方案-2"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#解决方案-2"}},[t._v("#")]),t._v(" 解决方案")]),t._v(" "),e("h4",{attrs:{id:"使用互斥锁-mutex-key"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#使用互斥锁-mutex-key"}},[t._v("#")]),t._v(" 使用互斥锁(mutex key)")]),t._v(" "),e("p",[t._v("业界比较常用的做法，是使用"),e("code",[t._v("mutex")]),t._v("互斥锁。简单地来说，就是在缓存失效的时候（判断拿出来的值为空），不是立即去load db，而是先使用缓存工具的某些带成功操作返回值的操作（比如Redis的SETNX或者Memcache的ADD）去set一个mutex key，当操作返回成功时，再进行load db的操作并回设缓存；否则，就重试整个get缓存的方法。")]),t._v(" "),e("h4",{attrs:{id:"提前-使用互斥锁-mutex-key"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#提前-使用互斥锁-mutex-key"}},[t._v("#")]),t._v(' "提前"使用互斥锁(mutex key)')]),t._v(" "),e("p",[t._v("在value内部设置1个超时值(timeout1), timeout1比实际的redis timeout(timeout2)小。当从cache读取到timeout1发现它已经过期时候，马上延长timeout1并重新设置到cache。然后再从数据库加载数据并设置到\ncache中。伪代码如下：")]),t._v(" "),e("h4",{attrs:{id:"永远不过期"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#永远不过期"}},[t._v("#")]),t._v(' "永远不过期"')]),t._v(" "),e("p",[t._v("这里的“永远不过期”包含两层意思：")]),t._v(" "),e("blockquote",[e("p",[t._v("(1) 从redis上看，确实没有设置过期时间，这就保证了，不会出现热点key过期问题，也就是“物理”不过期。"),e("br"),t._v("\n(2) 从功能上看，如果不过期，那不就成静态的了吗？所以我们把过期时间存在key对应的value里，如果发现要过期了，通过一个后台的异步线程进行缓存的构建，也就是“逻辑”过期。")])]),t._v(" "),e("h2",{attrs:{id:"缓存雪崩"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#缓存雪崩"}},[t._v("#")]),t._v(" 缓存雪崩")]),t._v(" "),e("p",[t._v("缓存雪崩是指在我们设置缓存时采用了相同的过期时间，导致缓存在某一时刻同时失效，请求全部转发到DB，DB瞬时压力过重雪崩。")]),t._v(" "),e("h3",{attrs:{id:"解决方案-3"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#解决方案-3"}},[t._v("#")]),t._v(" 解决方案")]),t._v(" "),e("p",[t._v("缓存失效时的雪崩效应对底层系统的冲击非常可怕。大多数系统设计者考虑用加锁或者队列的方式保证缓存的单线 程（进程）写，从而避免失效时大量的并发请求落到底层存储系统上。这里分享一个简单方案就时讲缓存失效时间分散开，比如我们可以在原有的失效时间基础上增加一个随机值，比如1-5分钟随机，这样每一个缓存的过期时间的重复率就会降低，就很难引发集体失效的事件。")])])}),[],!1,null,null,null);e.default=r.exports}}]);